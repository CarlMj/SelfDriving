# -*- coding: utf-8 -*-
"""SelfDrive.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ne9u-RuEJeQ0hyjB6OSLvC1OqmW8okh7
"""

!pip install git+https://github.com/aleju/imgaug

!pip install --upgrade scikit-image

import random
import numpy as np
import matplotlib.pyplot as plt
import keras
import matplotlib.image as mpimg
import cv2
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten
from keras.optimizers import Adam
from imgaug import augmenters as ia                                             #we will need to augment the data we have to reduce any bias
import os, ntpath                                                               #ntpath is the same as os.path except it can handle non Windows OS paths

!git clone https://github.com/CarlMj/SelfDriving.git

!cd SelfDriving

!ls SelfDriving
data = pd.read_csv("SelfDriving/driving_log.csv", names = ["center", "left", "right", "steering", "throttle", "reverse", "speed"])
print(data.head())
#we will only work with the center camera images
data['center'] = data['center'].apply(lambda x: ntpath.basename(x))
print(data.head())

print(len(data['center']))

#Visualize the distribution of data
hist, bins = np.histogram(data['steering'], 25)
#plt.bar(bins[:-1], hist, width = 0.04)
centered_bins = (bins[:-1] + bins[1:]) / 2.0
plt.bar(centered_bins, hist, width = 0.04)
plt.xlabel("steering angle")
#as it is show the data is biased towards predicting 0 for steering angle, lets find a threshold beyond which we will cut the number of data in each bin
threshold = 300
plt.plot((-1, 1), (threshold, threshold))
plt.show()

from sklearn.utils import shuffle
to_be_removed = []                                                              #list to collect indices of removable data
for i in range(25):
  lst = []                                                                      #list to collect indices
  for j in range(len(data['steering'])):
    if data['steering'][j] <= bins[i+1] and data['steering'][j] >= bins[i]:     #this means if the steering anlge falls in the bin
      lst.append(j)
  lst = shuffle(lst)                                                            #we need to shuffle the list in order to avoid truncating only the final portion of the road
  to_be_removed.extend(lst[threshold:])

data.drop(data.index[to_be_removed], inplace=True)
hist, b = np.histogram(data['steering'], 25)
centered_bins = (b[:-1] + b[1:]) / 2.0
plt.bar(centered_bins, hist, width = 0.04)
threshold = 300
plt.plot((-1, 1), (threshold, threshold))
plt.show()

# now lets extract our data and labels. we are only going to work with center images for simplicity
from sklearn.model_selection import train_test_split
imagepath = np.array(data['center'])
steer = np.array(data['steering'])
# print(imagepath.shape, imagepath.dtype)
# print(steer.shape, steer.dtype)
X_train, X_test, y_train, y_test = train_test_split(imagepath, steer, test_size = 0.2, random_state = 1)
print(X_test.shape, X_test[0])

print(steer[0])

#
def zoom(image):
  zoom = ia.Affine(scale=(1, 1.3))
  image = zoom.augment_image(image)
  return image

def pan(image):
  pan = ia.Affine(translate_percent={"x": (-0.1, 0.1), "y":(-0.1, 0.1)})
  image = pan.augment_image(image)
  return image

def darken(image):
  darken = ia.Multiply((0.2, 1.2))                       #multiplies all the intensity values by something - experience shows darkening the image helps better rather than brightening it
  image = darken.augment_image(image)
  return image

def flip(image, steering):
  image = cv2.flip(image, 1)                    #second argument 1 means horizontal flip, 0 vertical flip and -1 means combination of horizontal and vertical
  steering = -1*steering
  return image, steering

def augmentor(image, steering):
  image = mpimg.imread(os.path.join('SelfDriving', 'IMG', image))
  if np.random.rand() > 0.5:               #this if statements are there to avoid performing all augments on all images. adds randomness.
    image = zoom(image)
  if np.random.rand() > 0.5:
    image = pan(image)
  if np.random.rand() > 0.5:
    image = darken(image)
  if np.random.rand() > 0.5:
    image, steering = flip(image, steering)
  return image, steering

def preprocess(image):
  image = image[60:137, :, :]                                                   #first we cut the crap from our image. Like color of the sky is not important for us.
  image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)                                #We change the color channel since Nvidia model that will be implemented will work best with this channel
  image = cv2.GaussianBlur(image, (3, 3), 0)                                    #reduce the noise and smooth out the image
  image = cv2.resize(image, (200, 66))                                          #this is not necassary but Nvidia model has been trained using this size of images so will probably perform better on this size
  image = image / 255
  return image

s = X_train[0]
s = mpimg.imread(os.path.join('SelfDriving', 'IMG', s))
q = cv2.cvtColor(s, cv2.COLOR_RGB2YUV)                                     #reduce the noise and smooth out the image
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 10))
axs[0].imshow(s)
axs[1].imshow(q)
plt.show()

def batch_generator(images, steerings, batch_size, train):
  while True:
    imagebatch = []
    steerbatch = []
    indices = np.random.randint(len(images), size=batch_size)
    if train:
      maps = list(map(augmentor, images[indices], steerings[indices]))
      imagebatch, steerbatch = zip(*maps)
    else:
      imagebatch = list(map(mpimg.imread, 'SelfDriving/' + 'IMG/' + images[indices]))
      steerbatch = steerings[indices]
      
    imagebatch = list(map(preprocess, imagebatch))
    yield (np.asarray(imagebatch), np.asarray(steerbatch))

def nvidia():
  model = Sequential()
  #subsample defines the strides of the kernel by which it traverses
  model.add(Convolution2D(24, (5, 5), subsample=(2, 2), input_shape=(66, 200, 3), activation='elu'))
  #we use elu instead of relu so that nodes dont die
  model.add(Convolution2D(36, (5, 5), subsample=(2, 2), activation='elu'))
  model.add(Convolution2D(48, (5, 5), subsample=(2, 2), activation='elu'))
  #by this point the input has become pretty small so no need for stride change Also size of the kernel should change
  model.add(Convolution2D(64, (3, 3), activation='elu'))                        
  model.add(Convolution2D(64, (3, 3), activation='elu'))
  model.add(Flatten())
  model.add(Dense(100, activation='elu'))
  model.add(Dropout(0.0))
  model.add(Dense(50,  activation='elu'))
  model.add(Dropout(0.0))
  model.add(Dense(10,  activation='elu'))
  model.add(Dropout(0.3))
  model.add(Dense(1))
  model.compile(optimizer=Adam(0.005), loss='mse')
  return model

model1 = nvidia()
print(model1.summary())

# def preprocess(image):
#   image = mpimg.imread(os.path.join('SelfDriving', 'IMG', image))
#   image = image[60:137, :, :]                                                   #first we cut the crap from our image. Like color of the sky is not important for us.
#   image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)                                #We change the color channel since Nvidia model that will be implemented will work best with this channel
#   image = cv2.GaussianBlur(image, (3, 3), 0)                                    #reduce the noise and smooth out the image
#   image = cv2.resize(image, (200, 66))                                          #this is not necassary but Nvidia model has been trained using this size of images so will probably perform better on this size
#   image = image / 255
#   return image

# Preprocessed_train = np.asarray(list(map(preprocess, X_train)))
# Preprocessed_test = np.asarray(list(map(preprocess, X_test)))

# model = nvidia()
# print(model.summary())
# history = model.fit(Preprocessed_train, y_train, batch_size=100, epochs=10, validation_data = (Preprocessed_test, y_test), verbose=1, shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('loss')
plt.xlabel('Epoch')

model = nvidia()
print(model.summary())
history = model.fit_generator(batch_generator(X_train, y_train, batch_size=100, train=1), steps_per_epoch=300, epochs=10, validation_data = batch_generator(X_test, y_test, batch_size=100, train=0), validation_steps=200, verbose=1, shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('loss')
plt.xlabel('Epoch')

#model.save('NvidiaModel.h5')

# from google.colab import files
# files.download('NvidiaModel.h5')

#Server
import socketio
import numpy as np
from flask import Flask
import eventlet
from keras.models import load_model
import base64
from io import BytesIO
from PIL import Image
import cv2

sio = socketio.Server()

app = Flask(__name__)

speed_limit = 10
def preprocess(image):
  image = image[60:137, :, :]                                                   #first we cut the crap from our image. Like color of the sky is not important for us.
  image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)                                #We change the color channel since Nvidia model that will be implemented will work best with this channel
  image = cv2.GaussianBlur(image, (3, 3), 0)                                    #reduce the noise and smooth out the image
  image = cv2.resize(image, (200, 66))                                          #this is not necassary but Nvidia model has been trained using this size of images so will probably perform better on this size
  image = image / 255
  return image


@sio.on('telemetry')
def telemetry(sid, data):
    speed = float(data['speed'])
    image = Image.open(BytesIO(base64.b64decode(data['image'])))
    image = np.array(image)
    image = preprocess(image)
    image = np.array([image])
    steer = float(model.predict(image))
    throttle = 1.0 - speed/speed_limit
    send_steer(steer, throttle)

@sio.on('connect')
def connect(sid, environ):
    print('Connected')
    send_steer(0, 1)

def send_steer(angle, throttle):
    sio.emit('steer', data={
        'steering_angle': angle.__str__(),
        'throttle': throttle.__str__()
    })


if __name__ == '__main__':
    model = load_model('NvidiaModel3.h5')
    app = socketio.Middleware(sio, app)
    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)